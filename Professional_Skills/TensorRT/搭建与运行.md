# 第二章：搭建与运行

**TensorRT有两种阶段:第一个阶段是构建阶段\(build\)，第二种阶段是执行阶段\(production\).**

* **3.1、构建阶段\(build\)**
  ![image](https://note.youdao.com/yws/public/resource/a48e105e9dcf98f685bf69937a8ead17/xmlnote/A4A6EF17A0964F89A22BC732A5C19F2D/16563)

![](/Image/专业技能/TensorRT/TensorRT运行流程.png)

_\*这个plan是一个优化了的目标代码，可以序列化存储在内存或磁盘上。_

TensorRT构建阶段：TensorRT运行时需要三个文件来部署一个分类神经网络：一个网络体系结构文件\(deploy.prototxt\)，已训练的权值\(net.caffemodel\)和一个标签文件为每个输出类提供一个名称。另外，你必须定义batch size和输出层。

* **3.2、部署阶段**
  ![image](https://note.youdao.com/yws/public/resource/a48e105e9dcf98f685bf69937a8ead17/xmlnote/46743F3868424F70A8D4889F0B8F5EBF/16565)
  在部署阶段，使用构建阶段生成的PLAN文件来执行神经网络的前向传播。TensorRT以最小化延迟和最大化吞吐量运行优化了的网络。

## 4、开发环境搭建

4.1、**Windows C++环境搭建**

* 下载TensorRT

下载地址  
[https://developer.nvidia.com/nvidia-tensorrt-5x-download](https://developer.nvidia.com/nvidia-tensorrt-5x-download)

**注意查看自己电脑上的CUDA的版本和操作系统的版本**

1. 安装CUDA

在下面地址下载对于版本的CUDA版本  
[https://developer.nvidia.com/cuda-toolkit](https://developer.nvidia.com/cuda-toolkit)

1. 安装cuDNN

下载地址  
[https://developer.nvidia.com/rdp/cudnn-archive](https://developer.nvidia.com/rdp/cudnn-archive)

1. 把cudnn64\_7.dll拷贝到cuda9.0的安装目录下bin文件夹中，本文的路径是：C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\bin

2. 把TensorRT-5.1.5.0.Windows10.x86\_64.cuda-9.0.cudnn7.5.zip文件解压，然后把lib文件夹下的所有dll文件拷贝到cuda9.0的安装目录下bin文件夹中

**4.2、Ubuntu python环境搭建**

1. 安装cuda  
   1. 下载cuda。[https://developer.nvidia.com/cuda-toolkit](https://developer.nvidia.com/cuda-toolkit) 我下载的是10.0的版本  
   2. 使用命令安装

   ```
      sudo sh ./cuda_10.0.130_410.48_linux.run
   ```

   1. 使用默认安装路径，在显卡驱动已经安装的情况下，不需要再安装显卡驱动

   2. 配置环境变量

      ```
      vim /.bashrc
      # 在文件末尾加入以下内容
      export PATH="/usr/local/cuda-10.0/bin:$PATH"
      export LD_LIBRARY_PATH="/usr/local/cuda-10.0/lib64:$LD_LIBRARY_PATH"
      ```

2. 安装cudnn  
   1. 下载cudnn。这里需要和cuda tensorrt版本对应，在cuda10.0 tensorrt5.1.2版本中，需要安装cudnn7.5.0以上版本  
   2. 下载Linux压缩包文件，然后解压  
   3. 将cudnn中额内容拷贝到cuda安装的路径并赋予权限

   ![](/Image/专业技能/TensorRT/cudnn安装.png)

   1. 安装tensorrt

3. 下载tensorrt的Linux版本并解压

   1. 添加环境变量：

      ```
      $ vim ~/.bashrc # 打开环境变量文件
      # 将下面三个环境变量写入环境变量文件并保存
      export LD_LIBRARY_PATH=TensorRT解压路径/lib:$LD_LIBRARY_PATH
      export CUDA_INSTALL_DIR=/usr/local/cuda-9.0
      export CUDNN_INSTALL_DIR=/usr/local/cuda-9.0
      # 使刚刚修改的环境变量文件生效
      $ source ~/.bashrc
      ```

4. 安装Python的TensorRT包：  
   进到解压的TensorRT目录下的Python目录：

```
# 对于python2
$ sudo pip2 install tensorrt-XXX-cp27-cp27mu-linux_x86_64.whl
# 对于python3
$ sudo pip3 install tensorrt-XXX-cp35-cp35m-linux_x86_64.whl
```

1. 测试TensorRT是否安装成功，进入Python编辑器加载tensorrt：

```
>>> import tensorrt
>>> tensorrt.__version__
```

会输出TensorRT的版本号，即安装成功

1. 转到uff目录下安装uff包：

```
# 对于python2
$ sudo pip2 install uff-0.1.0rc0-py2.py3-none-any.whl
# 对于python3
$ sudo pip3 install uff-0.1.0rc0-py2.py3-none-any.whl
```

测试：

```
$ which convert-to-uff
```

会输出uff的安装路径。

## TensorFlow2.0安装

```
pip install tensorflow-gpu==2.0.0-alpha0 -i https://pypi.tuna.tsinghua.edu.cn/simple
# 使用了清华镜像源
```

## 安装 graphsurgeon

1. 到TensorRT目录下的graphsurgeon目录安装graphsurgeon

```
pip install --user graphsurgeon......
```



