# 第二章：搭建与运行

**TensorRT有两种阶段:第一个阶段是构建阶段\(build\)，第二种阶段是执行阶段\(production\).**

**1、构建阶段\(build\)**
  ![image](https://note.youdao.com/yws/public/resource/a48e105e9dcf98f685bf69937a8ead17/xmlnote/A4A6EF17A0964F89A22BC732A5C19F2D/16563)

![](/Image/专业技能/TensorRT/TensorRT运行流程.png)

_\*这个plan是一个优化了的目标代码，可以序列化存储在内存或磁盘上。_

TensorRT构建阶段：TensorRT运行时需要三个文件来部署一个分类神经网络：一个网络体系结构文件\(deploy.prototxt\)，已训练的权值\(net.caffemodel\)和一个标签文件为每个输出类提供一个名称。另外，你必须定义batch size和输出层。

**2、部署阶段**
  ![image](https://note.youdao.com/yws/public/resource/a48e105e9dcf98f685bf69937a8ead17/xmlnote/46743F3868424F70A8D4889F0B8F5EBF/16565)
  在部署阶段，使用构建阶段生成的PLAN文件来执行神经网络的前向传播。TensorRT以最小化延迟和最大化吞吐量运行优化了的网络。

## 开发环境搭建

### 1、**Windows C++环境搭建**

1.1. 下载TensorRT

下载地址  
[https://developer.nvidia.com/nvidia-tensorrt-5x-download](https://developer.nvidia.com/nvidia-tensorrt-5x-download)

**注意查看自己电脑上的CUDA的版本和操作系统的版本**

1.2.  安装CUDA

在下面地址下载对于版本的CUDA版本  
[https://developer.nvidia.com/cuda-toolkit](https://developer.nvidia.com/cuda-toolkit)

1.3.  安装cuDNN

下载地址  
[https://developer.nvidia.com/rdp/cudnn-archive](https://developer.nvidia.com/rdp/cudnn-archive)

1.3.1.  把cudnn64\_7.dll拷贝到cuda9.0的安装目录下bin文件夹中，本文的路径是：C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\bin

1.3.2.  把TensorRT-5.1.5.0.Windows10.x86\_64.cuda-9.0.cudnn7.5.zip文件解压，然后把lib文件夹下的所有dll文件拷贝到cuda9.0的安装目录下bin文件夹中

**这里需要注意的是一个版本的对应，对于cuda 、cudnn、TensorRT之间的版本必须对应。目前最新版的TensorRT只最低支持cudnn7.5.0以上的版本。**

### 2、**Ubuntu python环境搭建**

2.1. 安装cuda  
   2.1.1. 下载cuda。[https://developer.nvidia.com/cuda-toolkit](https://developer.nvidia.com/cuda-toolkit) 我下载的是10.0的版本  
   2.1.2. 使用命令安装

   ```
      sudo sh ./cuda_10.0.130_410.48_linux.run
   ```

   1. 使用默认安装路径，在显卡驱动已经安装的情况下，不需要再安装显卡驱动

   2. 配置环境变量
      ```
      vim /.bashrc
      # 在文件末尾加入以下内容
      export PATH="/usr/local/cuda-10.0/bin:$PATH"
      export LD_LIBRARY_PATH="/usr/local/cuda-10.0/lib64:$LD_LIBRARY_PATH"
      ```

2.2. 安装cudnn  
   1. 下载cudnn。这里需要和cuda tensorrt版本对应，在cuda10.0 tensorrt5.1.2版本中，需要安装cudnn7.5.0以上版本  
   2. 下载Linux压缩包文件，然后解压  
   3. 将cudnn中额内容拷贝到cuda安装的路径并赋予权限

   ![](/Image/专业技能/TensorRT/cudnn安装.png)

2.3. 安装tensorrt

   1. 下载tensorrt的Linux版本并解压

   2. 添加环境变量：

      ```
      $ vim ~/.bashrc # 打开环境变量文件
      # 将下面三个环境变量写入环境变量文件并保存
      export LD_LIBRARY_PATH=TensorRT解压路径/lib:$LD_LIBRARY_PATH
      export CUDA_INSTALL_DIR=/usr/local/cuda-9.0
      export CUDNN_INSTALL_DIR=/usr/local/cuda-9.0
      # 使刚刚修改的环境变量文件生效
      $ source ~/.bashrc
      ```

   3. 安装Python的TensorRT包：  
      进到解压的TensorRT目录下的Python目录：

    ```
    # 对于python2
    $ sudo pip2 install tensorrt-XXX-cp27-cp27mu-linux_x86_64.whl
    # 对于python3
    $ sudo pip3 install tensorrt-XXX-cp35-cp35m-linux_x86_64.whl
    ```

   4. 测试TensorRT是否安装成功，进入Python编辑器加载tensorrt：

    ```
    >>> import tensorrt
    >>> tensorrt.__version__
    ```
   会输出TensorRT的版本号，即安装成功

2.4. 转到uff目录下安装uff包：
```
# 对于python2
$ sudo pip2 install uff-0.1.0rc0-py2.py3-none-any.whl
# 对于python3
$ sudo pip3 install uff-0.1.0rc0-py2.py3-none-any.whl
```
测试：
```
$ which convert-to-uff
```
会输出uff的安装路径。

2.5. 安装 graphsurgeon
到TensorRT目录下的graphsurgeon目录安装graphsurgeon

```
# graphsurgeon......为其不同版本
pip install --user graphsurgeon......
```

### TensorFlow安装

**这里需要注意：对于TensorRT目前只支持TensorFlow1版本的。对于TensorFlow2.0版本的安装只有进行UFF文件的转换时会报没有tf.Graphdef的错误，这是由于在TensorFlow2.0的版本中移除了这个API。**

```
pip install tensorflow-gpu==1.14.0 -i https://pypi.tuna.tsinghua.edu.cn/simple
# 使用了清华镜像源
```

