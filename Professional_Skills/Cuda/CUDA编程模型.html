
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>第二章：CUDA编程模型 · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="CUDA执行模型.html" />
    
    
    <link rel="prev" href="基于CUDA的异构并行计算.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../../">
            
                <a href="../../">
            
                    
                    本书介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../../Computer_foundation/">
            
                <a href="../../Computer_foundation/">
            
                    
                    第一部分：计算机基础
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="../../Computer_foundation/Computer_composition/">
            
                <a href="../../Computer_foundation/Computer_composition/">
            
                    
                    第一模块：计算机组成原理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="../../Computer_foundation/Operating_System/">
            
                <a href="../../Computer_foundation/Operating_System/">
            
                    
                    第二模块：操作系统
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="../../Computer_foundation/Computer_Network/">
            
                <a href="../../Computer_foundation/Computer_Network/">
            
                    
                    第三模块：计算机网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="../../Computer_foundation/Data_Struct_Algorithms/">
            
                <a href="../../Computer_foundation/Data_Struct_Algorithms/">
            
                    
                    第四模块：数据结构与算法
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.4.1" data-path="../../Computer_foundation/Data_Struct_Algorithms/概论.html">
            
                <a href="../../Computer_foundation/Data_Struct_Algorithms/概论.html">
            
                    
                    第一章：概论
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.2" data-path="../../Computer_foundation/Data_Struct_Algorithms/线性表.html">
            
                <a href="../../Computer_foundation/Data_Struct_Algorithms/线性表.html">
            
                    
                    第二章：线性表
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.3" data-path="../../Computer_foundation/Data_Struct_Algorithms/栈和队列.html">
            
                <a href="../../Computer_foundation/Data_Struct_Algorithms/栈和队列.html">
            
                    
                    第三章：栈和队列
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.4" data-path="../../Computer_foundation/Data_Struct_Algorithms/串.html">
            
                <a href="../../Computer_foundation/Data_Struct_Algorithms/串.html">
            
                    
                    第四章：串
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.5" data-path="../../Computer_foundation/Data_Struct_Algorithms/数组和广义表.html">
            
                <a href="../../Computer_foundation/Data_Struct_Algorithms/数组和广义表.html">
            
                    
                    第五章：数组和广义表
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.6" data-path="../../Computer_foundation/Data_Struct_Algorithms/树和二叉树.html">
            
                <a href="../../Computer_foundation/Data_Struct_Algorithms/树和二叉树.html">
            
                    
                    第六章：树和二叉树
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.7" data-path="../../Computer_foundation/Data_Struct_Algorithms/图.html">
            
                <a href="../../Computer_foundation/Data_Struct_Algorithms/图.html">
            
                    
                    第七章：图
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.8" data-path="../../Computer_foundation/Data_Struct_Algorithms/动态存储管理.html">
            
                <a href="../../Computer_foundation/Data_Struct_Algorithms/动态存储管理.html">
            
                    
                    第八章：动态存储管理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.9" data-path="../../Computer_foundation/Data_Struct_Algorithms/查找.html">
            
                <a href="../../Computer_foundation/Data_Struct_Algorithms/查找.html">
            
                    
                    第九章：查找
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.10" data-path="../../Computer_foundation/Data_Struct_Algorithms/内部查找.html">
            
                <a href="../../Computer_foundation/Data_Struct_Algorithms/内部查找.html">
            
                    
                    第十章：内部查找
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.11" data-path="../../Computer_foundation/Data_Struct_Algorithms/外部查找.html">
            
                <a href="../../Computer_foundation/Data_Struct_Algorithms/外部查找.html">
            
                    
                    第十一章：外部查找
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.12" data-path="../../Computer_foundation/Data_Struct_Algorithms/文件.html">
            
                <a href="../../Computer_foundation/Data_Struct_Algorithms/文件.html">
            
                    
                    第十二章：文件
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../../Programming_Language/">
            
                <a href="../../Programming_Language/">
            
                    
                    第二部分：编程语言
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../../Programming_Language/Python/">
            
                <a href="../../Programming_Language/Python/">
            
                    
                    第一模块：Python
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../../Programming_Language/C++/">
            
                <a href="../../Programming_Language/C++/">
            
                    
                    第二模块：C++
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="../../Programming_Language/Design_Patterns/">
            
                <a href="../../Programming_Language/Design_Patterns/">
            
                    
                    第三模块：设计模式
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../">
            
                <a href="../">
            
                    
                    第三部分：专业技能
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="../TensorRT/">
            
                <a href="../TensorRT/">
            
                    
                    第一模块：TensorRT
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1.1" data-path="../TensorRT/TensorRT加速原理.html">
            
                <a href="../TensorRT/TensorRT加速原理.html">
            
                    
                    第一章：TensorRT加速原理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.1.2" data-path="../TensorRT/搭建与运行.html">
            
                <a href="../TensorRT/搭建与运行.html">
            
                    
                    第二章：搭建与运行
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.1.3" data-path="../TensorRT/核心API介绍.html">
            
                <a href="../TensorRT/核心API介绍.html">
            
                    
                    第三章：核心API介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.1.4" data-path="../TensorRT/编程流程及使用.html">
            
                <a href="../TensorRT/编程流程及使用.html">
            
                    
                    第四章：编程流程及使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.1.5" data-path="../TensorRT/遇到的问题和解决方法.html">
            
                <a href="../TensorRT/遇到的问题和解决方法.html">
            
                    
                    第五章：安装部署及遇到的问题和解决方法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.1.6" data-path="../TensorRT/TX2刷机.html">
            
                <a href="../TensorRT/TX2刷机.html">
            
                    
                    第六章：TX2刷机
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="../Opencv/">
            
                <a href="../Opencv/">
            
                    
                    第二模块：Opencv
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="../Tensorflow/">
            
                <a href="../Tensorflow/">
            
                    
                    第三模块：Tensorflow2.0
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="../Pytorch/">
            
                <a href="../Pytorch/">
            
                    
                    第四模块：Pytorch
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="./">
            
                <a href="./">
            
                    
                    第五模块：Cuda
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.5.1" data-path="基于CUDA的异构并行计算.html">
            
                <a href="基于CUDA的异构并行计算.html">
            
                    
                    第一章：基于CUDA的异构并行计算
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.4.5.2" data-path="CUDA编程模型.html">
            
                <a href="CUDA编程模型.html">
            
                    
                    第二章：CUDA编程模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5.3" data-path="CUDA执行模型.html">
            
                <a href="CUDA执行模型.html">
            
                    
                    第三章：CUDA执行模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5.4" data-path="全局内存.html">
            
                <a href="全局内存.html">
            
                    
                    第四章：全局内存
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5.5" data-path="共享内存和常量内存.html">
            
                <a href="共享内存和常量内存.html">
            
                    
                    第五章：共享内存和常量内存
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5.6" data-path="流和并发.html">
            
                <a href="流和并发.html">
            
                    
                    第六章：流和并发
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5.7" data-path="调整指令级原语.html">
            
                <a href="调整指令级原语.html">
            
                    
                    第七章：调整指令级原语
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5.8" data-path="GPU加速库和OpenACC.html">
            
                <a href="GPU加速库和OpenACC.html">
            
                    
                    第八章：GPU加速库和OpenACC
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5.9" data-path="多GPU编程.html">
            
                <a href="多GPU编程.html">
            
                    
                    第九章：多GPU编程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5.10" data-path="程序实现的注意事项.html">
            
                <a href="程序实现的注意事项.html">
            
                    
                    第十章：程序实现的注意事项
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../../Algorithm/">
            
                <a href="../../Algorithm/">
            
                    
                    第四部分：算法
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../../Algorithm/Traditional_machine_learning/">
            
                <a href="../../Algorithm/Traditional_machine_learning/">
            
                    
                    第一部分：传统机器学习算法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="../../Algorithm/Deep_Learning/">
            
                <a href="../../Algorithm/Deep_Learning/">
            
                    
                    第二部分：深度学习算法
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.2.1" data-path="../../Algorithm/Deep_Learning/深度学习基础算法/">
            
                <a href="../../Algorithm/Deep_Learning/深度学习基础算法/">
            
                    
                    第一篇：深度学习基础算法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.2" data-path="../../Algorithm/Deep_Learning/深度学习应用算法/">
            
                <a href="../../Algorithm/Deep_Learning/深度学习应用算法/">
            
                    
                    第二篇：深度学习应用算法
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.2.2.1" data-path="../../Algorithm/Deep_Learning/深度学习应用算法/目标分类算法.html">
            
                <a href="../../Algorithm/Deep_Learning/深度学习应用算法/目标分类算法.html">
            
                    
                    第一部分：目标分类算法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.2.2" data-path="../../Algorithm/Deep_Learning/深度学习应用算法/目标检测算法.html">
            
                <a href="../../Algorithm/Deep_Learning/深度学习应用算法/目标检测算法.html">
            
                    
                    第二部分：目标检测算法
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.2.2.2.1" data-path="../../Algorithm/Deep_Learning/深度学习应用算法/R-CNN.html">
            
                <a href="../../Algorithm/Deep_Learning/深度学习应用算法/R-CNN.html">
            
                    
                    R-CNN
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.2.2.2" data-path="../../Algorithm/Deep_Learning/深度学习应用算法/Fast R-CNN.html">
            
                <a href="../../Algorithm/Deep_Learning/深度学习应用算法/Fast R-CNN.html">
            
                    
                    Fast R-CNN
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.2.2.3" data-path="../../Algorithm/Deep_Learning/深度学习应用算法/Faster R-CNN.html">
            
                <a href="../../Algorithm/Deep_Learning/深度学习应用算法/Faster R-CNN.html">
            
                    
                    Faster R-CNN
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.2.2.4" data-path="../../Algorithm/Deep_Learning/深度学习应用算法/YoloV1.html">
            
                <a href="../../Algorithm/Deep_Learning/深度学习应用算法/YoloV1.html">
            
                    
                    YoloV1
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.2.2.5" data-path="../../Algorithm/Deep_Learning/深度学习应用算法/YoloV2.html">
            
                <a href="../../Algorithm/Deep_Learning/深度学习应用算法/YoloV2.html">
            
                    
                    YoloV2
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.2.2.6" data-path="../../Algorithm/Deep_Learning/深度学习应用算法/YoloV3.html">
            
                <a href="../../Algorithm/Deep_Learning/深度学习应用算法/YoloV3.html">
            
                    
                    YoloV3
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2.2.2.7" data-path="../../Algorithm/Deep_Learning/深度学习应用算法/SSD.html">
            
                <a href="../../Algorithm/Deep_Learning/深度学习应用算法/SSD.html">
            
                    
                    SSD
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.3" data-path="../../Algorithm/Reinforcement_Learning/">
            
                <a href="../../Algorithm/Reinforcement_Learning/">
            
                    
                    第三部分：强化学习算分
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.3.1" data-path="../../Algorithm/Reinforcement_Learning/强化学习基础.html">
            
                <a href="../../Algorithm/Reinforcement_Learning/强化学习基础.html">
            
                    
                    第一篇：强化学习基础
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.3.1.1" data-path="../../Algorithm/Reinforcement_Learning/马尔科夫决策过程.html">
            
                <a href="../../Algorithm/Reinforcement_Learning/马尔科夫决策过程.html">
            
                    
                    马尔科夫决策过程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.1.2" data-path="../../Algorithm/Reinforcement_Learning/基于模型的动态规划方法.html">
            
                <a href="../../Algorithm/Reinforcement_Learning/基于模型的动态规划方法.html">
            
                    
                    基于模型的动态规划方法
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.3.2" data-path="../../Algorithm/Reinforcement_Learning/基于值函数的强化学习方法.html">
            
                <a href="../../Algorithm/Reinforcement_Learning/基于值函数的强化学习方法.html">
            
                    
                    第二篇：基于值函数的强化学习⽅法
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.3.2.1" data-path="../../Algorithm/Reinforcement_Learning/基于蒙特卡罗的强化学习⽅法.html">
            
                <a href="../../Algorithm/Reinforcement_Learning/基于蒙特卡罗的强化学习⽅法.html">
            
                    
                    基于蒙特卡罗的强化学习⽅法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.2" data-path="../../Algorithm/Reinforcement_Learning/基于时间差分的强化学习⽅法.html">
            
                <a href="../../Algorithm/Reinforcement_Learning/基于时间差分的强化学习⽅法.html">
            
                    
                    基于时间差分的强化学习⽅法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.3" data-path="../../Algorithm/Reinforcement_Learning/基于值函数逼近的强化学习⽅法 .html">
            
                <a href="../../Algorithm/Reinforcement_Learning/基于值函数逼近的强化学习⽅法 .html">
            
                    
                    基于值函数逼近的强化学习⽅法
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.3.3" data-path="../../Algorithm/Reinforcement_Learning/基于直接策略搜索的强化学习⽅法.html">
            
                <a href="../../Algorithm/Reinforcement_Learning/基于直接策略搜索的强化学习⽅法.html">
            
                    
                    第三篇：基于直接策略搜索的强化学习⽅法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.4" data-path="../../Algorithm/Reinforcement_Learning/强化学习研究前沿.html">
            
                <a href="../../Algorithm/Reinforcement_Learning/强化学习研究前沿.html">
            
                    
                    第四篇：强化学习研究及前沿
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../.." >第二章：CUDA编程模型</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="&#x7B2C;&#x4E8C;&#x7AE0;&#xFF1A;cuda&#x7F16;&#x7A0B;&#x6A21;&#x578B;">&#x7B2C;&#x4E8C;&#x7AE0;&#xFF1A;CUDA&#x7F16;&#x7A0B;&#x6A21;&#x578B;</h1>
<h2 id="21&#x3001;cuda&#x7F16;&#x7A0B;&#x7ED3;&#x6784;">2.1&#x3001;CUDA&#x7F16;&#x7A0B;&#x7ED3;&#x6784;</h2>
<p>CUDA&#x7F16;&#x7A0B;&#x6A21;&#x578B;&#x4F7F;&#x7528;&#x7531;C&#x8BED;&#x8A00;&#x6269;&#x5C55;&#x751F;&#x6210;&#x7684;&#x6CE8;&#x91CA;&#x4EE3;&#x7801;&#x5728;&#x5F02;&#x6784;&#x8BA1;&#x7B97;&#x7CFB;&#x7EDF;&#x4E2D;&#x6267;&#x884C;&#x5E94;&#x7528;&#x7A0B;&#x5E8F;&#x3002;</p>
<p>&#x5728;&#x4E00;&#x4E2A;&#x5F02;&#x6784;&#x73AF;&#x5883;&#x4E2D;&#x5305;&#x542B;&#x591A;&#x4E2A;CPU&#x548C;GPU&#xFF0C;&#x6BCF;&#x4E2A;GPU&#x548C;CPU&#x7684;&#x5185;&#x5B58;&#x90FD;&#x7531;&#x4E00;&#x6761;PCI-Express&#x603B;&#x7EBF;</p>
<p>&#x5206;&#x9694;&#x5F00;&#x3002;&#x56E0;&#x6B64;&#xFF0C;&#x9700;&#x8981;&#x6CE8;&#x610F;&#x533A;&#x5206;&#x4EE5;&#x4E0B;&#x5185;&#x5BB9;&#x3002;</p>
<ul>
<li>&#x4E3B;&#x673A;&#xFF1A;CPU&#x53CA;&#x5176;&#x5185;&#x5B58;&#xFF08;&#x4E3B;&#x673A;&#x5185;&#x5B58;&#xFF09; </li>
<li>&#x8BBE;&#x5907;&#xFF1A;GPU&#x53CA;&#x5176;&#x5185;&#x5B58;&#xFF08;&#x8BBE;&#x5907;&#x5185;&#x5B58;&#xFF09; </li>
</ul>
<p>&#x4E3A;&#x4E86;&#x6E05;&#x695A;&#x5730;&#x6307;&#x660E;&#x4E0D;&#x540C;&#x7684;&#x5185;&#x5B58;&#x7A7A;&#x95F4;&#xFF0C;&#x4E3B;&#x673A;&#x5185;&#x5B58;&#x4E2D;&#x7684;&#x53D8;&#x91CF;&#x540D;&#x4EE5;h<em>&#x6216;host</em>&#x4E3A; &#x524D;&#x7F00;&#xFF0C;&#x8BBE;&#x5907;&#x5185;&#x5B58;&#x4E2D;&#x7684;&#x53D8;&#x91CF;&#x540D;&#x4EE5;d<em>&#x6216;device</em>&#x4E3A;&#x524D;&#x7F00;&#x3002;</p>
<p>&#x4E00;&#x4E2A;&#x5178;&#x578B;&#x7684;CUDA&#x7A0B;&#x5E8F;&#x5B9E;&#x73B0;&#x6D41;&#x7A0B;&#x9075;&#x5FAA;&#x4EE5;&#x4E0B;&#x6A21;&#x5F0F;&#x3002;</p>
<ol>
<li><p>&#x628A;&#x6570;&#x636E;&#x4ECE;CPU&#x5185;&#x5B58;&#x62F7;&#x8D1D;&#x5230;GPU&#x5185;&#x5B58;&#x3002;</p>
</li>
<li><p>&#x8C03;&#x7528;&#x6838;&#x51FD;&#x6570;&#x5BF9;&#x5B58;&#x50A8;&#x5728;GPU&#x5185;&#x5B58;&#x4E2D;&#x7684;&#x6570;&#x636E;&#x8FDB;&#x884C;&#x64CD;&#x4F5C;&#x3002;</p>
</li>
<li><p>&#x5C06;&#x6570;&#x636E;&#x4ECE;GPU&#x5185;&#x5B58;&#x4F20;&#x9001;&#x56DE;&#x5230;CPU&#x5185;&#x5B58;&#x3002;</p>
</li>
</ol>
<p><img src="../../Image/&#x4E13;&#x4E1A;&#x6280;&#x80FD;/CUDA/CUDA&#x5E94;&#x7528;&#x7A0B;&#x5E8F;.jpg" alt=""></p>
<h2 id="22&#x3001;&#x5185;&#x5B58;&#x7BA1;&#x7406;">2.2&#x3001;&#x5185;&#x5B58;&#x7BA1;&#x7406;</h2>
<p>&#x5728;CUDA&#x7F16;&#x7A0B;&#x4E2D;&#xFF0C;&#x5BF9;&#x4E8E;&#x5185;&#x5B58;&#x7684;&#x7BA1;&#x7406;&#x5206;&#x4E3A;&#x5BF9;&#x4E3B;&#x673A;&#x5185;&#x5B58;&#x7684;&#x7BA1;&#x7406;&#xFF0C;&#x548C;&#x5BF9;&#x8BBE;&#x5907;&#x7684;&#x5185;&#x5B58;&#x7684;&#x7BA1;&#x7406;&#x3002;</p>
<p>&#x76F8;&#x5173;&#x4E3B;&#x673A;&#x548C;&#x8BBE;&#x5907;&#x7684;&#x5185;&#x5B58;&#x51FD;&#x6570;&#xFF1A;</p>
<p><img src="../../Image/&#x4E13;&#x4E1A;&#x6280;&#x80FD;/CUDA/&#x5185;&#x5B58;&#x51FD;&#x6570;.jpg" alt=""></p>
<p>cudaMemcpy&#x51FD;&#x6570;&#x8D1F;&#x8D23;&#x4E3B;&#x673A;&#x548C;&#x8BBE;&#x5907;&#x4E4B;&#x95F4;&#x7684;&#x6570;&#x636E;&#x4F20;&#x8F93;&#xFF0C;&#x5176;&#x51FD;&#x6570;&#x539F;&#x578B;&#x4E3A;&#xFF1A;</p>
<pre><code>cudaError_t cudaMemcpy (void* dst,const void* src,size_t count, cudaMemcpyKind kind)
</code></pre><p>&#x6B64;&#x51FD;&#x6570;&#x4ECE;src&#x6307;&#x5411;&#x7684;&#x6E90;&#x5B58;&#x50A8;&#x533A;&#x590D;&#x5236;&#x4E00;&#x5B9A;&#x6570;&#x91CF;&#x7684;&#x5B57;&#x8282;&#x5230;dst&#x6307;&#x5411;&#x7684;&#x76EE;&#x6807;&#x5B58;&#x50A8;&#x533A;&#x3002;&#x590D;&#x5236;&#x65B9;&#x5411;</p>
<p>&#x7531;kind&#x6307;&#x5B9A;&#xFF0C;&#x5176;&#x4E2D;&#x7684;kind&#x6709;&#x4EE5;&#x4E0B;&#x51E0;&#x79CD;&#x3002;</p>
<ul>
<li>[ ] cudaMemcpyHostToHost</li>
<li>[ ] cudaMemcpyHostTODevice</li>
<li>[ ] cudaMemcpyDeviceToHost</li>
<li>[ ] cudaMemcpyDeviceToDevice</li>
</ul>
<p>&#x8FD9;&#x4E2A;&#x51FD;&#x6570;&#x4EE5;&#x540C;&#x6B65;&#x65B9;&#x5F0F;&#x6267;&#x884C;&#xFF0C;&#x56E0;&#x4E3A;&#x5728;cudaMemcpy&#x51FD;&#x6570;&#x8FD4;&#x56DE;&#x4EE5;&#x53CA;&#x4F20;&#x8F93;&#x64CD;&#x4F5C;&#x5B8C;&#x6210;&#x4E4B;&#x524D;&#x4E3B;&#x673A;</p>
<p>&#x5E94;&#x7528;&#x7A0B;&#x5E8F;&#x662F;&#x963B;&#x585E;&#x7684;&#x3002;&#x9664;&#x4E86;&#x5185;&#x6838;&#x542F;&#x52A8;&#x4E4B;&#x5916;&#x7684;CUDA&#x8C03;&#x7528;&#x90FD;&#x4F1A;&#x8FD4;&#x56DE;&#x4E00;&#x4E2A;&#x9519;&#x8BEF;&#x7684;&#x679A;&#x4E3E;&#x7C7B;&#x578B;cuda</p>
<p>Error_t&#x3002;&#x5982;&#x679C;GPU&#x5185;&#x5B58;&#x5206;&#x914D;&#x6210;&#x529F;&#xFF0C;&#x51FD;&#x6570;&#x8FD4;&#x56DE;&#xFF1A;</p>
<p><code>cudaErrorMemoryAllocation</code></p>
<p>&#x5426;&#x5219;&#x8FD4;&#x56DE;&#xFF1A;</p>
<p><code>cudaErrorMemoryAlloction</code></p>
<p>&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x4EE5;&#x4E0B;CUDA&#x8FD0;&#x884C;&#x65F6;&#x51FD;&#x6570;&#x5C06;&#x9519;&#x8BEF;&#x4EE3;&#x7801;&#x8F6C;&#x5316;&#x4E3A;&#x53EF;&#x8BFB;&#x7684;&#x9519;&#x8BEF;&#x6D88;&#x606F;&#xFF1A;</p>
<p><code>char* cudaGetErrorString(cudaError_t error)</code></p>
<p>cudaGetErrorString&#x51FD;&#x6570;&#x548C;C&#x8BED;&#x8A00;&#x4E2D;&#x7684;strerror&#x51FD;&#x6570;&#x7C7B;&#x4F3C;&#x3002;</p>
<hr>
<p>CUDA&#x7F16;&#x7A0B;&#x6A21;&#x578B;&#x4ECE;GPU&#x67B6;&#x6784;&#x4E2D;&#x62BD;&#x8C61;&#x51FA;&#x4E00;&#x4E2A;&#x5185;&#x5B58;&#x5C42;&#x6B21;&#x7ED3;&#x6784;&#x3002;&#x56FE;&#x4E0B;&#x6240;&#x793A;&#x7684;&#x662F;&#x4E00;&#x4E2A;&#x7B80;&#x5316;&#x7684;</p>
<p>GPU&#x5185;&#x5B58;&#x7ED3;&#x6784;&#xFF0C;&#x5B83;&#x4E3B;&#x8981;&#x5305;&#x542B;&#x4E24;&#x90E8;&#x5206;&#xFF1A;&#x5168;&#x5C40;&#x5185;&#x5B58;&#x548C;&#x5171;&#x4EAB;&#x5185;&#x5B58;&#x3002;</p>
<p><img src="../../Image/&#x4E13;&#x4E1A;&#x6280;&#x80FD;/CUDA/cuda&#x62BD;&#x8C61;&#x5185;&#x5B58;&#x6A21;&#x578B;.jpg" alt=""></p>
<p>&#x5168;&#x5C40;&#x5185;&#x5B58;&#x7C7B;&#x4F3C;&#x4E8E;CPU&#x7684;&#x7CFB;&#x7EDF;&#x5185;&#x5B58;&#xFF0C;&#x800C;&#x5171;&#x4EAB;&#x5185;&#x5B58;&#x7C7B;&#x4F3C;&#x4E8E;CPU&#x7684;&#x7F13;&#x5B58;&#x3002;&#x7136;&#x800C;GPU&#x7684;&#x5171;&#x4EAB;&#x5185;&#x5B58;&#x53EF;&#x4EE5;&#x7531;CUDA &#x7684;&#x5185;&#x6838;&#x76F4;&#x63A5;&#x63A7;&#x5236;&#x3002;</p>
<p><strong>&#x5BF9;&#x6BD4;&#x4F8B;&#x5B50;--&#x77E9;&#x9635;&#x76F8;&#x52A0;&#xFF1A;</strong></p>
<ul>
<li><p>CPU&#x4E0A;&#x8BA1;&#x7B97;</p>
<pre><code>#include &lt;stdlib.h&gt;
#include &lt;time.h&gt;

/*
 * This example demonstrates a simple vector sum on the host. sumArraysOnHost
 * sequentially iterates through vector elements on the host.
 */

void sumArraysOnHost(float *A, float *B, float *C, const int N)
{
    for (int idx = 0; idx &lt; N; idx++)
    {
        C[idx] = A[idx] + B[idx];
    }

}

void initialData(float *ip, int size)
{
    // generate different seed for random number
    time_t t;
    srand((unsigned) time(&amp;t));

    for (int i = 0; i &lt; size; i++)
    {
        ip[i] = (float)(rand() &amp; 0xFF) / 10.0f;
    }

    return;
}

int main(int argc, char **argv)
{
    int nElem = 1024;
    size_t nBytes = nElem * sizeof(float);

    float *h_A, *h_B, *h_C;
    h_A = (float *)malloc(nBytes);
    h_B = (float *)malloc(nBytes);
    h_C = (float *)malloc(nBytes);

    initialData(h_A, nElem);
    initialData(h_B, nElem);

    sumArraysOnHost(h_A, h_B, h_C, nElem);

    free(h_A);
    free(h_B);
    free(h_C);

    return(0);
}
</code></pre></li>
<li><p>GPU&#x4E0A;&#x8BA1;&#x7B97;</p>
<pre><code>#include &quot;../common/common.h&quot;
#include &lt;cuda_runtime.h&gt;
#include &lt;stdio.h&gt;

/*
&#x8FD9;&#x4E2A;&#x4F8B;&#x5B50;&#x5728;GPU&#x548C;&#x4E3B;&#x673A;&#x4E0A;&#x6F14;&#x793A;&#x4E86;&#x4E00;&#x4E2A;&#x7B80;&#x5355;&#x7684;&#x5411;&#x91CF;&#x548C;&#x3002;
* sumArraysOnGPU&#x5C06;&#x5411;&#x91CF;&#x548C;&#x7684;&#x5DE5;&#x4F5C;&#x5206;&#x5272;&#x5230;CUDA&#x7EBF;&#x7A0B;&#x4E0A;
* GPU&#x3002;&#x4E3A;&#x4E86;&#x7B80;&#x5355;&#x8D77;&#x89C1;&#xFF0C;&#x5728;&#x8FD9;&#x4E2A;&#x5C0F;&#x793A;&#x4F8B;&#x4E2D;&#x53EA;&#x4F7F;&#x7528;&#x4E86;&#x4E00;&#x4E2A;&#x7EBF;&#x7A0B;&#x5757;&#x3002;
* sumArraysOnHost&#x987A;&#x5E8F;&#x904D;&#x5386;&#x4E3B;&#x673A;&#x4E0A;&#x7684;&#x5411;&#x91CF;&#x5143;&#x7D20;&#x3002;
&#x8FD9;&#x4E2A;&#x7248;&#x672C;&#x7684;sumarray&#x589E;&#x52A0;&#x4E86;&#x4E3B;&#x673A;&#x5B9A;&#x65F6;&#x5668;&#x6765;&#x6D4B;&#x91CF;GPU&#x548C;CPU
*&#x6027;&#x80FD;
 */
// &#x68C0;&#x67E5;&#x7ED3;&#x679C;&#x662F;&#x5426;&#x5B8C;&#x6210;
void checkResult(float *hostRef, float *gpuRef, const int N)
{
    double epsilon = 1.0E-8;
    bool match = 1;

    for (int i = 0; i &lt; N; i++)
    {
        if (abs(hostRef[i] - gpuRef[i]) &gt; epsilon)
        {
            match = 0;
            printf(&quot;Arrays do not match!\n&quot;);
            printf(&quot;host %5.2f gpu %5.2f at current %d\n&quot;, hostRef[i],
                   gpuRef[i], i);
            break;
        }
    }

    if (match) printf(&quot;Arrays match.\n\n&quot;);

    return;
}

//&#x521D;&#x59CB;&#x5316;&#x5411;&#x91CF;
void initialData(float *ip, int size)
{
    // generate different seed for random number
    time_t t;
    srand((unsigned) time(&amp;t));

    for (int i = 0; i &lt; size; i++)
    {
        ip[i] = (float)( rand() &amp; 0xFF ) / 10.0f;
    }

    return;
}
// &#x5728;&#x4E3B;&#x673A;&#x8BBE;&#x5907;&#x8FDB;&#x884C;&#x5411;&#x91CF;&#x8BA1;&#x7B97;
void sumArraysOnHost(float *A, float *B, float *C, const int N)
{
    for (int idx = 0; idx &lt; N; idx++)
    {
        C[idx] = A[idx] + B[idx];
    }
}
// &#x6838;&#x51FD;&#x6570;&#xFF0C;&#x5728;GPU&#x4E0A;&#x8FDB;&#x884C;&#x5411;&#x91CF;&#x8BA1;&#x7B97;
__global__ void sumArraysOnGPU(float *A, float *B, float *C, const int N)
{
    int i = blockIdx.x * blockDim.x + threadIdx.x;

    if (i &lt; N) C[i] = A[i] + B[i];
}

int main(int argc, char **argv)
{
    printf(&quot;%s Starting...\n&quot;, argv[0]);

    // &#x8BBE;&#x7F6E;GPU&#x7684;&#x4F7F;&#x7528;&#x7F16;&#x53F7;
    int dev = 0;
    // GPU&#x8BBE;&#x5907;&#x7684;&#x4FE1;&#x606F;&#x5BF9;&#x8C61;
    cudaDeviceProp deviceProp;
    // &#x83B7;&#x53D6;&#x6307;&#x5B9A;&#x7F16;&#x53F7;&#x7684;GPU&#x4FE1;&#x606F;
    CHECK(cudaGetDeviceProperties(&amp;deviceProp, dev));
    printf(&quot;Using Device %d: %s\n&quot;, dev, deviceProp.name);
    //&#x8BBE;&#x7F6E;&#x4F7F;&#x7528;&#x7684;GPU
    CHECK(cudaSetDevice(dev));

    // &#x8BBE;&#x7F6E;vectors&#x7684;&#x5927;&#x5C0F;
    int nElem = 1 &lt;&lt; 24;
    printf(&quot;Vector size %d\n&quot;, nElem);

    // &#x4E3B;&#x673A;&#x5185;&#x5B58;&#x5206;&#x914D;&#x5927;&#x5C0F;
    size_t nBytes = nElem * sizeof(float);

    float *h_A, *h_B, *hostRef, *gpuRef;
    h_A     = (float *)malloc(nBytes);
    h_B     = (float *)malloc(nBytes);
    hostRef = (float *)malloc(nBytes);
    gpuRef  = (float *)malloc(nBytes);

    double iStart, iElaps;

    // &#x521D;&#x59CB;&#x5316;&#x4E3B;&#x673A;&#x7AEF;&#x5185;&#x5B58;&#x6570;&#x636E;
    iStart = seconds();
    initialData(h_A, nElem);
    initialData(h_B, nElem);
    iElaps = seconds() - iStart;
    printf(&quot;initialData Time elapsed %f sec\n&quot;, iElaps);
    memset(hostRef, 0, nBytes);
    memset(gpuRef,  0, nBytes);

    // &#x5728;&#x4E3B;&#x673A;&#x7AEF;&#x8FDB;&#x884C;&#x5411;&#x91CF;&#x7684;&#x8BA1;&#x7B97;
    iStart = seconds();
    sumArraysOnHost(h_A, h_B, hostRef, nElem);
    iElaps = seconds() - iStart;
    printf(&quot;sumArraysOnHost Time elapsed %f sec\n&quot;, iElaps);

    // &#x5206;&#x914D;GPU&#x7AEF;&#x5185;&#x5B58;
    float *d_A, *d_B, *d_C;
    CHECK(cudaMalloc((float**)&amp;d_A, nBytes));
    CHECK(cudaMalloc((float**)&amp;d_B, nBytes));
    CHECK(cudaMalloc((float**)&amp;d_C, nBytes));

    // &#x5C06;&#x4E3B;&#x673A;&#x7AEF;&#x7684;&#x5185;&#x5B58;&#x6570;&#x636E;&#x62F7;&#x8D1D;&#x5230;GPU&#x7AEF;&#x7684;&#x5168;&#x5C40;&#x5185;&#x5B58;&#x533A;
    CHECK(cudaMemcpy(d_A, h_A, nBytes, cudaMemcpyHostToDevice));
    CHECK(cudaMemcpy(d_B, h_B, nBytes, cudaMemcpyHostToDevice));
    CHECK(cudaMemcpy(d_C, gpuRef, nBytes, cudaMemcpyHostToDevice));

    // &#x5728;&#x4E3B;&#x673A;&#x7AEF;&#x8C03;&#x7528;&#x6838;&#x51FD;&#x6570;
    /*
    &#x5F53;&#x6570;&#x636E;&#x88AB;&#x8F6C;&#x79FB;&#x5230;GPU&#x7684;&#x5168;&#x5C40;&#x5185;&#x5B58;&#x540E;&#xFF0C;&#x4E3B;&#x673A;&#x7AEF;&#x8C03;&#x7528;&#x6838;&#x51FD;&#x6570;&#x5728;GPU&#x4E0A;&#x8FDB;&#x884C;&#x6570;&#x7EC4;&#x6C42;&#x548C;&#x3002;&#x4E00;&#x65E6; &#x5185;&#x6838;&#x88AB;&#x8C03;&#x7528;&#xFF0C;&#x63A7;&#x5236;&#x6743;&#x7ACB;&#x523B;&#x88AB;&#x4F20;&#x56DE;&#x4E3B;&#x673A;&#xFF0C;&#x8FD9;&#x6837;&#x7684;&#x8BDD;&#xFF0C;&#x5F53;&#x6838;&#x51FD;&#x6570;&#x5728;GPU&#x4E0A;&#x8FD0;&#x884C;&#x65F6;&#xFF0C;&#x4E3B;&#x673A;&#x53EF;&#x4EE5;&#x6267; &#x884C;&#x5176;&#x4ED6;&#x51FD;&#x6570;&#x3002;&#x56E0;&#x6B64;&#xFF0C;&#x5185;&#x6838;&#x4E0E;&#x4E3B;&#x673A;&#x662F;&#x5F02;&#x6B65;&#x7684;&#x3002;
    */
    int iLen = 512;
    dim3 block (iLen);
    dim3 grid  ((nElem + block.x - 1) / block.x);

    iStart = seconds();
    sumArraysOnGPU&lt;&lt;&lt;grid, block&gt;&gt;&gt;(d_A, d_B, d_C, nElem);
    CHECK(cudaDeviceSynchronize());
    //&#x4E3B;&#x673A;&#x5F97;&#x65F6;&#x95F4;&#x8BA1;&#x7B97;
    iElaps = seconds() - iStart;
    printf(&quot;sumArraysOnGPU &lt;&lt;&lt;  %d, %d  &gt;&gt;&gt;  Time elapsed %f sec\n&quot;, grid.x,
           block.x, iElaps);

    // &#x68C0;&#x67E5;&#x6838;&#x51FD;&#x6570;&#x662F;&#x5426;&#x6709;&#x9519;&#x8BEF;
    CHECK(cudaGetLastError()) ;

    // &#x5C06;GPU&#x7AEF;&#x7684;&#x8BA1;&#x7B97;&#x7ED3;&#x6784;&#x62F7;&#x8D1D;&#x5230;&#x4E3B;&#x673A;&#x7AEF;
    CHECK(cudaMemcpy(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost));

    // &#x68C0;&#x67E5;&#x8BA1;&#x7B97;&#x7684;&#x7ED3;&#x679C;
    checkResult(hostRef, gpuRef, nElem);

    // &#x91CA;&#x653E;&#x8BBE;&#x5907;&#x7AEF;&#x7684;&#x5185;&#x5B58;
    CHECK(cudaFree(d_A));
    CHECK(cudaFree(d_B));
    CHECK(cudaFree(d_C));

    // &#x91CA;&#x653E;&#x4E3B;&#x673A;&#x7AEF;&#x7684;&#x5185;&#x5B58;
    free(h_A);
    free(h_B);
    free(hostRef);
    free(gpuRef);

    return(0);
}
</code></pre><p>&#x5F53;&#x6570;&#x636E;&#x88AB;&#x8F6C;&#x79FB;&#x5230;GPU&#x7684;&#x5168;&#x5C40;&#x5185;&#x5B58;&#x540E;&#xFF0C;&#x4E3B;&#x673A;&#x7AEF;&#x8C03;&#x7528;&#x6838;&#x51FD;&#x6570;&#x5728;GPU&#x4E0A;&#x8FDB;&#x884C;&#x6570;&#x7EC4;&#x6C42;&#x548C;&#x3002;&#x4E00;&#x65E6; &#x5185;&#x6838;&#x88AB;&#x8C03;&#x7528;&#xFF0C;&#x63A7;&#x5236;&#x6743;&#x7ACB;&#x523B;&#x88AB;&#x4F20;&#x56DE;&#x4E3B;&#x673A;&#xFF0C;&#x8FD9;&#x6837;&#x7684;&#x8BDD;&#xFF0C;&#x5F53;&#x6838;&#x51FD;&#x6570;&#x5728;GPU&#x4E0A;&#x8FD0;&#x884C;&#x65F6;&#xFF0C;&#x4E3B;&#x673A;&#x53EF;&#x4EE5;&#x6267; &#x884C;&#x5176;&#x4ED6;&#x51FD;&#x6570;&#x3002;&#x56E0;&#x6B64;&#xFF0C;&#x5185;&#x6838;&#x4E0E;&#x4E3B;&#x673A;&#x662F;&#x5F02;&#x6B65;&#x7684;&#x3002;</p>
<p>&#x5F53;&#x5185;&#x6838;&#x5728;GPU&#x4E0A;&#x5B8C;&#x6210;&#x4E86;&#x5BF9;&#x6240;&#x6709;&#x6570;&#x7EC4;&#x5143;&#x7D20;&#x7684;&#x5904;&#x7406;&#x540E;&#xFF0C;&#x5176;&#x7ED3;&#x679C;&#x5C06;&#x4EE5;&#x6570;&#x7EC4;d_C&#x7684;&#x5F62;&#x5F0F;&#x5B58;&#x50A8;&#x5728;</p>
<p>GPU&#x7684;&#x5168;&#x5C40;&#x5185;&#x5B58;&#x4E2D;&#xFF0C;&#x7136;&#x540E;&#x7528;cudaMemcpy&#x51FD;&#x6570;&#x628A;&#x7ED3;&#x679C;&#x4ECE;GPU&#x590D;&#x5236;&#x56DE;&#x5230;&#x4E3B;&#x673A;&#x7684;&#x6570;&#x7EC4;gpuRef&#x4E2D;&#x3002;</p>
<p><code>cudaMemcpy(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost)</code></p>
<p>cudaMemcpy&#x7684;&#x8C03;&#x7528;&#x4F1A;&#x5BFC;&#x81F4;&#x4E3B;&#x673A;&#x8FD0;&#x884C;&#x963B;&#x585E;&#x3002;cudaMemcpyDeviceToHost&#x7684;&#x4F5C;&#x7528;&#x5C31;&#x662F;&#x5C06;&#x5B58;&#x50A8;&#x5728;GPU&#x4E0A;&#x7684;&#x6570;&#x7EC4;d_c&#x4E2D;&#x7684;&#x7ED3;&#x679C;&#x590D;&#x5236;&#x5230;gpuRef&#x4E2D;&#x3002;</p>
<p><strong>&#x6CE8;&#x610F;&#xFF1A;&#x4E3B;&#x673A;&#x4E0E;&#x8BBE;&#x5907;&#x4E4B;&#x95F4;&#x7684;&#x5185;&#x5B58;&#x62F7;&#x8D1D;&#xFF0C;&#x4E00;&#x5B9A;&#x8981;&#x7528;cudaMemcpy&#x51FD;&#x6570;&#x3002;&#x5982;&#x679C;&#x8FD0;&#x7528;gpuRef = d_C&#x5219;&#x7A0B;&#x5E8F;&#x5728;&#x8FD0;&#x884C;&#x65F6;&#x5C06;&#x4F1A;&#x76F4;&#x63A5;&#x5954;&#x6E83;&#x3002;</strong></p>
</li>
</ul>
<h2 id="23&#x3001;&#x7EBF;&#x7A0B;&#x7BA1;&#x7406;">2.3&#x3001;&#x7EBF;&#x7A0B;&#x7BA1;&#x7406;</h2>
<p>&#x5F53;&#x6838;&#x51FD;&#x6570;&#x5728;&#x4E3B;&#x673A;&#x7AEF;&#x542F;&#x52A8;&#x65F6;&#xFF0C;&#x5B83;&#x7684;&#x6267;&#x884C;&#x4F1A;&#x79FB;&#x52A8;&#x5230;&#x8BBE;&#x5907;&#x4E0A;&#xFF0C;&#x6B64;&#x65F6;&#x8BBE;&#x5907;&#x4E2D;&#x4F1A;&#x4EA7;&#x751F;&#x5927;&#x91CF;&#x7684;&#x7EBF;&#x7A0B;</p>
<p>&#x5E76;&#x4E14;&#x6BCF;&#x4E2A;&#x7EBF;&#x7A0B;&#x90FD;&#x6267;&#x884C;&#x7531;&#x6838;&#x51FD;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x8BED;&#x53E5;&#x3002;&#x4E86;&#x89E3;&#x5982;&#x4F55;&#x7EC4;&#x7EC7;&#x7EBF;&#x7A0B;&#x662F;CUDA&#x7F16;&#x7A0B;&#x7684;&#x4E00;&#x4E2A;&#x5173;&#x952E;&#x90E8;</p>
<p>&#x5206;&#x3002;CUDA&#x660E;&#x786E;&#x4E86;&#x7EBF;&#x7A0B;&#x5C42;&#x6B21;&#x62BD;&#x8C61;&#x7684;&#x6982;&#x5FF5;&#x4EE5;&#x4FBF;&#x4E8E;&#x4F60;&#x7EC4;&#x7EC7;&#x7EBF;&#x7A0B;&#x3002;&#x8FD9;&#x662F;&#x4E00;&#x4E2A;&#x4E24;&#x5C42;&#x7684;&#x7EBF;&#x7A0B;&#x5C42;&#x6B21;&#x7ED3;</p>
<p>&#x6784;&#xFF0C;&#x7531;&#x7EBF;&#x7A0B;&#x5757;&#x548C;&#x7EBF;&#x7A0B;&#x5757;&#x7F51;&#x683C;&#x6784;&#x6210;&#xFF0C;&#x5982;&#x4E0B;&#x56FE;&#x6240;&#x793A;&#x3002;</p>
<p><img src="../../Image/&#x4E13;&#x4E1A;&#x6280;&#x80FD;/CUDA/GPU&#x7EBF;&#x7A0B;&#x62BD;&#x8C61;.jpg" alt=""></p>
<p>&#x7531;&#x4E00;&#x4E2A;&#x5185;&#x6838;&#x542F;&#x52A8;&#x6240;&#x4EA7;&#x751F;&#x7684;&#x6240;&#x6709;&#x7EBF;&#x7A0B;&#x7EDF;&#x79F0;&#x4E3A;&#x4E00;&#x4E2A;&#x7F51;&#x683C;&#x3002;&#x540C;&#x4E00;&#x7F51;&#x683C;&#x4E2D;&#x7684;&#x6240;&#x6709;&#x7EBF;&#x7A0B;&#x5171;&#x4EAB;&#x76F8;&#x540C;</p>
<p>&#x7684;&#x5168;&#x5C40;&#x5185;&#x5B58;&#x7A7A;&#x95F4;&#x3002;&#x4E00;&#x4E2A;&#x7F51;&#x683C;&#x7531;&#x591A;&#x4E2A;&#x7EBF;&#x7A0B;&#x5757;&#x6784;&#x6210;&#xFF0C;&#x4E00;&#x4E2A;&#x7EBF;&#x7A0B;&#x5757;&#x5305;&#x542B;&#x4E00;&#x7EC4;&#x7EBF;&#x7A0B;&#xFF0C;&#x540C;&#x4E00;&#x7EBF;&#x7A0B;&#x5757;&#x5185;</p>
<p>&#x7684;&#x7EBF;&#x7A0B;&#x534F;&#x4F5C;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;<strong>&#x540C;&#x6B65;&#x3001;&#x5171;&#x4EAB;&#x5185;&#x5B58;</strong>&#x6765;&#x5B9E;&#x73B0;&#x3002;</p>
<p><strong>&#x4E0D;&#x540C;&#x5757;&#x5185;&#x7684;&#x7EBF;&#x7A0B;&#x4E0D;&#x80FD;&#x534F;&#x4F5C;&#x3002; </strong></p>
<p>&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x4EE5;&#x4E0B;&#x53D8;&#x91CF;&#x6765;&#x533A;&#x5206;&#x7EBF;&#x7A0B;&#x5757;&#x53CA;&#x7EBF;&#x7A0B;</p>
<pre><code>blockIdx.x
blockIdx.y
blockIdx.z
threadIdx.x
threadIdx.y
threadIdx.z
</code></pre><p>CUDA&#x53EF;&#x4EE5;&#x7EC4;&#x7EC7;&#x4E09;&#x7EF4;&#x7684;&#x7F51;&#x683C;&#x548C;&#x5757;&#x3002;&#x4E0A;&#x56FE;&#x5C55;&#x793A;&#x4E86;&#x4E00;&#x4E2A;&#x7EBF;&#x7A0B;&#x5C42;&#x6B21;&#x7ED3;&#x6784;&#x7684;&#x793A;&#x4F8B;&#xFF0C;&#x5176;&#x7ED3;&#x6784;&#x662F;</p>
<p>&#x4E00;&#x4E2A;&#x5305;&#x542B;&#x4E8C;&#x7EF4;&#x5757;&#x7684;&#x4E8C;&#x7EF4;&#x7F51;&#x683C;&#x3002;&#x7F51;&#x683C;&#x548C;&#x5757;&#x7684;&#x7EF4;&#x5EA6;&#x7531;&#x4E0B;&#x5217;&#x4E24;&#x4E2A;&#x5185;&#x7F6E;&#x53D8;&#x91CF;&#x6307;&#x5B9A;&#x3002;</p>
<ul>
<li>blockDim&#xFF08;&#x7EBF;&#x7A0B;&#x5757;&#x7684;&#x7EF4;&#x5EA6;&#xFF0C;&#x7528;&#x6BCF;&#x4E2A;&#x7EBF;&#x7A0B;&#x5757;&#x4E2D;&#x7684;&#x7EBF;&#x7A0B;&#x6570;&#x6765;&#x8868;&#x793A;&#xFF09; </li>
<li>gridDim&#xFF08;&#x7EBF;&#x7A0B;&#x683C;&#x7684;&#x7EF4;&#x5EA6;&#xFF0C;&#x7528;&#x6BCF;&#x4E2A;&#x7EBF;&#x7A0B;&#x683C;&#x4E2D;&#x7684;&#x7EBF;&#x7A0B;&#x6570;&#x6765;&#x8868;&#x793A;&#xFF09; </li>
</ul>
<p>&#x5B83;&#x4EEC;&#x662F;dim3&#x7C7B;&#x578B;&#x7684;&#x53D8;&#x91CF;&#xFF0C;&#x662F;&#x57FA;&#x4E8E;uint3&#x5B9A;&#x4E49;&#x7684;&#x6574;&#x6570;&#x578B;&#x5411;&#x91CF;&#xFF0C;&#x7528;&#x6765;&#x8868;&#x793A;&#x7EF4;&#x5EA6;&#x3002;&#x5F53;&#x5B9A;&#x4E49;&#x4E00;&#x4E2A;</p>
<p>dim3&#x7C7B;&#x578B;&#x7684;&#x53D8;&#x91CF;&#x65F6;&#xFF0C;&#x6240;&#x6709;&#x672A;&#x6307;&#x5B9A;&#x7684;&#x5143;&#x7D20;&#x90FD;&#x88AB;&#x521D;&#x59CB;&#x5316;&#x4E3A;1&#x3002;dim3&#x7C7B;&#x578B;&#x53D8;&#x91CF;&#x4E2D;&#x7684;&#x6BCF;&#x4E2A;&#x7EC4;&#x4EF6;&#x53EF;&#x4EE5;</p>
<p>&#x901A;&#x8FC7;&#x5B83;&#x7684;x&#x3001;y&#x3001;z&#x5B57;&#x6BB5;&#x83B7;&#x5F97;&#x3002;&#x5982;&#x4E0B;&#x6240;&#x793A;&#x3002;</p>
<pre><code>blockDIm.x
blockDIm.y
blockDIm.z
</code></pre><ul>
<li>&#x68C0;&#x67E5;&#x7F51;&#x683C;&#x3001;&#x7EBF;&#x7A0B;&#x5757;&#x7684;&#x7EF4;&#x5EA6;&#x4FE1;&#x606F;</li>
</ul>
<pre><code>#include &quot;../common/common.h&quot;
#include &lt;cuda_runtime.h&gt;
#include &lt;stdio.h&gt;

/*
 * Display the dimensionality of a thread block and grid from the host and
 * device.
 */

__global__ void checkIndex(void)
{
    printf(&quot;threadIdx:(%d, %d, %d)\n&quot;, threadIdx.x, threadIdx.y, threadIdx.z);
    printf(&quot;blockIdx:(%d, %d, %d)\n&quot;, blockIdx.x, blockIdx.y, blockIdx.z);

    printf(&quot;blockDim:(%d, %d, %d)\n&quot;, blockDim.x, blockDim.y, blockDim.z);
    printf(&quot;gridDim:(%d, %d, %d)\n&quot;, gridDim.x, gridDim.y, gridDim.z);

}

int main(int argc, char **argv)
{
    // define total data element
    int nElem = 6;

    // define grid and block structure
    dim3 block(3);
    dim3 grid((nElem + block.x - 1) / block.x);

    // check grid and block dimension from host side
    printf(&quot;grid.x %d grid.y %d grid.z %d\n&quot;, grid.x, grid.y, grid.z);
    printf(&quot;block.x %d block.y %d block.z %d\n&quot;, block.x, block.y, block.z);

    // check grid and block dimension from device side
    checkIndex&lt;&lt;&lt;grid, block&gt;&gt;&gt;();

    // reset device before you leave
    CHECK(cudaDeviceReset());

    return(0);
}
</code></pre><ul>
<li>&#x8F93;&#x51FA;&#x7ED3;&#x679C;</li>
</ul>
<p><img src="../../Image/&#x4E13;&#x4E1A;&#x6280;&#x80FD;/CUDA/&#x7A0B;&#x5E8F;&#x8F93;&#x51FA;&#x7ED3;&#x679C;1.jpg" alt=""></p>
<p><strong>&#x5BF9;&#x4E8E;&#x4E00;&#x4E2A;&#x7ED9;&#x5B9A;&#x7684;&#x6570;&#x636E;&#x5927;&#x5C0F;&#xFF0C;&#x786E;&#x5B9A;&#x7F51;&#x683C;&#x548C;&#x5757;&#x5C3A;&#x5BF8;&#x7684;&#x4E00;&#x822C;&#x6B65;&#x9AA4;&#x4E3A;&#xFF1A; </strong></p>
<ul>
<li>&#x786E;&#x5B9A;&#x5757;&#x7684;&#x5927;&#x5C0F; </li>
<li>&#x5728;&#x5DF2;&#x77E5;&#x6570;&#x636E;&#x5927;&#x5C0F;&#x548C;&#x5757;&#x5927;&#x5C0F;&#x7684;&#x57FA;&#x7840;&#x4E0A;&#x8BA1;&#x7B97;&#x7F51;&#x683C;&#x7EF4;&#x5EA6;</li>
</ul>
<p>&#x8981;&#x786E;&#x5B9A;&#x5757;&#x5C3A;&#x5BF8;&#xFF0C;&#x901A;&#x5E38;&#x9700;&#x8981;&#x8003;&#x8651;&#xFF1A;</p>
<ul>
<li>&#x5185;&#x6838;&#x7684;&#x6027;&#x80FD;&#x7279;&#x6027; </li>
<li>GPU&#x8D44;&#x6E90;&#x7684;&#x9650;&#x5236; </li>
</ul>
<h2 id="24&#x3001;&#x542F;&#x52A8;&#x4E00;&#x4E2A;cuda&#x6838;&#x51FD;&#x6570;">2.4&#x3001;&#x542F;&#x52A8;&#x4E00;&#x4E2A;CUDA&#x6838;&#x51FD;&#x6570;</h2>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="基于CUDA的异构并行计算.html" class="navigation navigation-prev " aria-label="Previous page: 第一章：基于CUDA的异构并行计算">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="CUDA执行模型.html" class="navigation navigation-next " aria-label="Next page: 第三章：CUDA执行模型">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"第二章：CUDA编程模型","level":"1.4.5.2","depth":3,"next":{"title":"第三章：CUDA执行模型","level":"1.4.5.3","depth":3,"path":"Professional_Skills/Cuda/CUDA执行模型.md","ref":"Professional_Skills/Cuda/CUDA执行模型.md","articles":[]},"previous":{"title":"第一章：基于CUDA的异构并行计算","level":"1.4.5.1","depth":3,"path":"Professional_Skills/Cuda/基于CUDA的异构并行计算.md","ref":"Professional_Skills/Cuda/基于CUDA的异构并行计算.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["livereload"],"pluginsConfig":{"livereload":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"Professional_Skills/Cuda/CUDA编程模型.md","mtime":"2019-08-12T06:57:23.225Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-08-22T05:13:30.331Z"},"basePath":"../..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../../gitbook/gitbook.js"></script>
    <script src="../../gitbook/theme.js"></script>
    
        
        <script src="../../gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

