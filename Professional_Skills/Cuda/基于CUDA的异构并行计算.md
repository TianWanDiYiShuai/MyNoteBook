# 第一章：基于CUDA的异构并行计算

## 1、并行计算

  从纯粹的计算视角来看，并行计算可以被定义为计算的一种形式，在这种形式下，计

算机可以同时进行许多运算，计算原则是一个大的问题往往可以被划分为很多可以同时解

决的小问题。

  从程序员的角度来说，一个很自然的疑问，就是如何将并发计算映射到计算机上。假

设你有许多计算资源，并行计算可以被定义为同时使用许多计算资源（核心或计算机）来

执行并发计算，一个大的问题可以被分解成多个小问题，然后在不同的计算资源上并行处

理这些小问题。并行计算的软件和硬件层面是紧密联系的。事实上，并行计算通常涉及两

个不同的计算技术领域。

* 计算机架构（硬件方面）

* 并行程序设计（软件方面）

![](/Image/专业技能/CUDA/串行和并行比较.jpg)

在应用程序中有两种基本的并行类型。 

- 任务并行 

- 数据并行 

## 2、异构计算

&emsp;&emsp;一个典型的异构计算节点包括两个多核CPU插槽和两个或更多个的众核GPU。GPU不 

是一个独立运行的平台而是CPU的协处理器。因此，GPU必须通过PCIe总线与基于CPU的 

主机相连来进行操作，如下图所示。这就是为什么CPU所在的位置被称作主机端而GPU 

所在的位置被称作设备端。

![](/Image/专业技能/CUDA/CPU-GPU异构.jpg)

一个异构应用包括两个部分。 

- 主机代码 

- 设备代码 

&emsp;&emsp;主机代码在CPU上运行，设备代码在GPU上运行。异构平台上执行的应用通常由CPU 

初始化。在设备端加载计算密集型任务之前，CPU代码负责管理设备端的环境、代码和数 

据。

&emsp;&emsp;在计算密集型应用中，往往有很多并行数据的程序段。GPU就是用来提高这些并行数 

据的执行速度的。当使用CPU上的一个与其物理上分离开的硬件组件来提高应用中的计算 

密集部分的执行速度时，这个组件就成为了一个硬件加速器。GPU可以说是最为常见的硬 

件加速器。

![](/Image/专业技能/CUDA/异构计算结构图.jpg)

### 2.1、GPU与CPU线程区别

&emsp;&emsp;CPU上的线程通常是重量级的实体。操作系统必须交替线程使用启用或关闭CPU执行 

通道以提供多线程处理功能。上下文的切换缓慢且开销大。 

GPU上的线程是高度轻量级的。在一个典型的系统中会有成千上万的线程排队等待工 

作。如果GPU必须等待一组线程执行结束，那么它只要调用另一组线程执行其他任务即 

可。

&emsp;&emsp;CPU的核被设计用来尽可能减少一个或两个线程运行时间的延迟，而GPU的核是用来 

处理大量并发的、轻量级的线程，以最大限度地提高吞吐量。 

现在，四核CPU上可以同时运行16个线程，如果CPU支持超线程可支持多至32个线 

程。

&emsp;&emsp;现代的NVIDIA GPU在每个多处理器上最多可以并发支持1536个同时活跃的线程。有 

16个多处理器的GPU，可以并发支持超过24000个同时活跃的线程



## 3、 CUDA：一种异构计算平台 

&emsp;&emsp;CUDA是一种通用的并行计算平台和编程模型，它利用NVIDIA GPU中的并行计算引 

擎能更有效地解决复杂的计算问题。通过使用CUDA，你可以像在CPU上那样，通过GPU 

来进行计算。 

&emsp;&emsp;CUDA平台可以通过CUDA加速库、编译器指令、应用编程接口以及行业标准程序语 

言的扩展（包括C、C++、Fortran、Python）来使用。

![](/Image/专业技能/CUDA/GPU计算应用程序.jpg)

CUDA提供了两层API来管理GPU设备和组织线程

![](/Image/专业技能/CUDA/CUDAAPI.jpg)

- CUDA驱动API 

- CUDA运行时API 

  ![](/Image/专业技能/CUDA/NVCC编译器.jpg)


### 4、CUDA编程hello world

```
#include <stdio.h>
__global__ void helloFromGPU(void)
{
	printf("Hello World from GPU!\n");
}

int main(void)
{
	printf("Hello World from GPU!\n");

	helloFromGPU <<<1,10>>>();
	cudaDeviceReset();
	return 0;
}
```

编译：

`nvcc  hello.cu -o hello`

## 5、CUDA编程结构

1. 分配GPU内存。 

2. 从CPU内存中拷贝数据到GPU内存。 

3. 调用CUDA内核函数来完成程序指定的运算。 

4. 将数据从GPU拷回CPU内存。 

5. 释放GPU内存空间



